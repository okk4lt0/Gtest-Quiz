# app.py
# Gæ¤œå®šã‚¯ã‚¤ã‚ºï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³=Gemini â†’ å¤±æ•—æ™‚ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰ï¼‹ ä½¿ç”¨é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼
# ä¾å­˜: streamlit, google-generativeai

import os
import json
from pathlib import Path
import random
import time
from datetime import datetime, timedelta, timezone
import streamlit as st

# ===== åŸºæœ¬è¨­å®š =====
st.set_page_config(page_title="Gæ¤œå®šã‚¯ã‚¤ã‚ºã‚¢ãƒ—ãƒª", page_icon="ğŸ§ ", layout="centered")

APP_DIR = Path(__file__).parent
DATA_DIR = APP_DIR / "data"
BANK_DIR = APP_DIR / "bank"                      # å•é¡Œãƒãƒ³ã‚¯ã®å ´æ‰€
BANK_FILE = BANK_DIR / "question_bank.jsonl"     # 1è¡Œ1å•ã® JSON Lines

# ===== ãƒ¡ãƒ¼ã‚¿ãƒ¼è¨­å®šï¼ˆæ¨å®šå€¤ã€‚å¿…è¦ãªã‚‰Sidebarã§å¤‰æ›´å¯èƒ½ï¼‰ =====
DEFAULT_DAILY_LIMIT = int(os.getenv("GEMINI_DAILY_LIMIT", "5"))   # Freeç›¸å½“ã®ç›®å®‰
DEFAULT_RPM_LIMIT   = int(os.getenv("GEMINI_RPM_LIMIT", "2"))     # 1åˆ†ã‚ãŸã‚Šã®ç›®å®‰

METER_FILE = BANK_DIR / "usage_meter.json"  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå±¥æ­´ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ï¼ˆStreamlit Cloudã§ã‚‚Gitè¿½è·¡å¯¾è±¡å¤–ãŒæœ›ã¾ã—ã„ï¼‰

JST = timezone(timedelta(hours=9))

# ===== çŠ¶æ…‹ç¢ºä¿ =====
def ensure_state():
    ss = st.session_state
    ss.setdefault("question", None)     # ç¾åœ¨ã®å‡ºé¡Œï¼ˆdictï¼‰
    ss.setdefault("picked", None)       # "A"ã€œ"D"
    ss.setdefault("result", None)       # æ¡ç‚¹çµæœ
    ss.setdefault("mode", None)         # "online" / "offline"
    ss.setdefault("model_name", None)   # å®Ÿéš›ã«ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«å
    ss.setdefault("last_error", "")     # ç›´è¿‘ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¤±æ•—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
ensure_state()

# ===== ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ =====
def load_meter() -> dict:
    """usage_meter.json ã‚’èª­ã¿è¾¼ã¿ã€‚ãªã‘ã‚Œã°åˆæœŸåŒ–ã€‚"""
    BANK_DIR.mkdir(parents=True, exist_ok=True)
    if METER_FILE.exists():
        try:
            return json.loads(METER_FILE.read_text(encoding="utf-8"))
        except Exception:
            pass
    return {
        "tz": "JST",
        "daily_limit": DEFAULT_DAILY_LIMIT,
        "rpm_limit": DEFAULT_RPM_LIMIT,
        "today": datetime.now(JST).strftime("%Y-%m-%d"),
        "calls_today": 0,
        "call_timestamps": [],   # ISOæ–‡å­—åˆ—ã®é…åˆ—ï¼ˆç›´è¿‘æ•°åˆ†ï¼‰
        "last_429_at": None
    }

def save_meter(m: dict):
    METER_FILE.write_text(json.dumps(m, ensure_ascii=False, indent=2), encoding="utf-8")

def reset_if_new_day(m: dict):
    today = datetime.now(JST).strftime("%Y-%m-%d")
    if m.get("today") != today:
        m["today"] = today
        m["calls_today"] = 0
        m["call_timestamps"] = []
        m["last_429_at"] = None

def record_call(m: dict, ok: bool, is_429: bool):
    now = datetime.now(JST)
    # ç›´è¿‘1åˆ†ã®å±¥æ­´ã‚’ç¶­æŒ
    cutoff = now - timedelta(minutes=2)
    kept = []
    for t in m.get("call_timestamps", []):
        try:
            dt = datetime.fromisoformat(t)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=JST)
        except Exception:
            continue
        if dt >= cutoff:
            kept.append(dt.astimezone(JST).isoformat())
    kept.append(now.isoformat())
    m["call_timestamps"] = kept

    if ok:
        m["calls_today"] = int(m.get("calls_today", 0)) + 1
    if is_429:
        m["last_429_at"] = now.isoformat()

def rpm_window_info(m: dict):
    """ç›´è¿‘60ç§’ã§ã®å‘¼ã³å‡ºã—æ•°ã¨ã€æ¬¡ã«å®‰å…¨ã«ãªã‚‹ã¾ã§ã®ç›®å®‰ç§’æ•°ã€‚"""
    now = datetime.now(JST)
    window_start = now - timedelta(seconds=60)
    cnt = 0
    oldest = None
    for t in m.get("call_timestamps", []):
        try:
            dt = datetime.fromisoformat(t)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=JST)
        except Exception:
            continue
        if dt >= window_start:
            cnt += 1
            if oldest is None or dt < oldest:
                oldest = dt
    cooldown_sec = 0
    if cnt >= int(m.get("rpm_limit", DEFAULT_RPM_LIMIT)) and oldest:
        # æœ€å¤ã®å‘¼ã³å‡ºã—ã‹ã‚‰60ç§’çµŒéã™ã‚‹ã¾ã§
        cooldown_sec = max(0, 60 - int((now - oldest).total_seconds()))
    return cnt, cooldown_sec

def get_daily_progress(m: dict):
    limit = max(1, int(m.get("daily_limit", DEFAULT_DAILY_LIMIT)))
    used = int(m.get("calls_today", 0))
    ratio = min(1.0, used / limit)
    remaining = max(0, limit - used)
    return used, limit, remaining, ratio

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå•é¡Œãƒãƒ³ã‚¯ï¼‰ =====
def normalize_item(item: dict) -> dict | None:
    """è¡Œã”ã¨ã®è¾æ›¸ã‚’ã‚¢ãƒ—ãƒªå†…éƒ¨ã®çµ±ä¸€å½¢å¼ã«å¤‰æ›"""
    if not isinstance(item, dict):
        return None
    q = item.get("question")
    choices = item.get("choices")
    correct = item.get("correct") or item.get("answer")

    # choices ãŒé…åˆ—ãªã‚‰ Aã€œD ã«å‰²ã‚Šå½“ã¦
    if isinstance(choices, list) and len(choices) == 4:
        choices = {k: v for k, v in zip(["A", "B", "C", "D"], choices)}

    if not q or not isinstance(choices, dict) or len(choices) != 4:
        return None
    if correct not in ["A", "B", "C", "D"]:
        return None

    return {
        "source": item.get("source", "offline"),
        "question": q,
        "choices": choices,
        "correct": correct,
        "explanations": item.get("explanations", {})
    }

def read_jsonl(path: Path) -> list[dict]:
    items = []
    if path.exists():
        with path.open("r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    raw = json.loads(line)
                except Exception:
                    continue
                norm = normalize_item(raw)
                if norm:
                    items.append(norm)
    return items

def load_offline_bank() -> list[dict]:
    bank = read_jsonl(BANK_FILE)
    if bank:
        return bank
    # ãƒãƒ³ã‚¯ãŒç©ºã®ã¨ãã®æœ€ä½é™ã®1å•
    return [{
        "source": "offline_default",
        "question": "æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®èª¬æ˜ã¨ã—ã¦æœ€ã‚‚é©åˆ‡ãªã®ã¯ã©ã‚Œï¼Ÿ",
        "choices": {
            "A": "å…¥åŠ›ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹",
            "B": "æ­£è§£ãƒ©ãƒ™ãƒ«ãªã—ã§æ§‹é€ ã‚’è¦‹ã¤ã‘ã‚‹",
            "C": "å ±é…¬æœ€å¤§åŒ–ã®è¡Œå‹•ã‚’å­¦ç¿’ã™ã‚‹",
            "D": "ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ã¿ã‚’æ‰±ã†å­¦ç¿’æ³•"
        },
        "correct": "A",
        "explanations": {
            "A": "æ•™å¸«ã‚ã‚Šå­¦ç¿’ã¯å…¥åŠ›ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢ã§å­¦ç¿’ã—ã¾ã™ã€‚",
            "B": "ã“ã‚Œã¯æ•™å¸«ãªã—å­¦ç¿’ã®èª¬æ˜ã§ã™ã€‚",
            "C": "ã“ã‚Œã¯å¼·åŒ–å­¦ç¿’ã®èª¬æ˜ã§ã™ã€‚",
            "D": "å­¦ç¿’è¨­å®šã®èª¬æ˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
        }
    }]

# ===== Geminiï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼‰ =====
def get_gemini_api_key() -> str | None:
    try:
        return st.secrets["GEMINI_API_KEY"]
    except Exception:
        return os.getenv("GEMINI_API_KEY")

@st.cache_data(show_spinner=False, ttl=900)
def list_available_models(api_key: str) -> list[str]:
    import google.generativeai as genai
    genai.configure(api_key=api_key)
    models = []
    try:
        for m in genai.list_models():
            methods = getattr(m, "supported_generation_methods", []) or []
            if "generateContent" in methods:
                models.append(m.name)
    except Exception:
        # å–å¾—å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€™è£œ
        models = ["gemini-2.5-flash", "gemini-2.0-flash", "gemini-2.0-flash-lite"]
    return sorted(models)

def generate_with_gemini(model_name: str, meter: dict) -> dict:
    """Geminiã§1å•ç”Ÿæˆã—å†…éƒ¨å½¢å¼ã§è¿”ã™ã€‚å¤±æ•—æ™‚ã¯ä¾‹å¤–ã‚’é€å‡ºã€‚ãƒ¡ãƒ¼ã‚¿ãƒ¼è¨˜éŒ²è¾¼ã¿ã€‚"""
    api_key = get_gemini_api_key()
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    import google.generativeai as genai
    genai.configure(api_key=api_key)

    sys_prompt = (
        "ã‚ãªãŸã¯Gæ¤œå®šå¯¾ç­–ã®å•é¡Œä½œæˆè€…ã§ã™ã€‚å››æŠå•é¡Œã‚’1å•ã ã‘æ—¥æœ¬èªã§ä½œæˆã€‚"
        "é¸æŠè‚¢ã¯Aã€œDã§1ã¤ã ã‘æ­£è§£ã€‚å„é¸æŠè‚¢ã«1æ–‡ã®è§£èª¬ã‚’ä»˜ã‘ã‚‹ã€‚"
        "å†…å®¹ã¯æ©Ÿæ¢°å­¦ç¿’/ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°/çµ±è¨ˆ/å€«ç†ã®åŸºç¤ç¯„å›²ã‹ã‚‰ã€‚"
    )
    generation_config = {
        "response_mime_type": "application/json",
        "temperature": 0.6,
        "max_output_tokens": 600,
    }
    payload = {
        "question": "å•é¡Œæ–‡ï¼ˆ1ã€œ2æ–‡ï¼‰",
        "choices": {"A": "â€¦", "B": "â€¦", "C": "â€¦", "D": "â€¦"},
        "correct": "A|B|C|D ã®ã„ãšã‚Œã‹1ã¤",
        "explanations": {"A": "â€¦", "B": "â€¦", "C": "â€¦", "D": "â€¦"}
    }

    # å‘¼ã¶ç›´å‰ã«ãƒ¡ãƒ¼ã‚¿ãƒ¼æ—¥ä»˜ã‚’åŒæœŸ
    reset_if_new_day(meter)
    try:
        model = genai.GenerativeModel(model_name, generation_config=generation_config)
        resp = model.generate_content([{"role": "user", "parts": [sys_prompt, json.dumps(payload, ensure_ascii=False)]}])
        text = ""
        try:
            text = resp.candidates[0].content.parts[0].text
        except Exception:
            text = getattr(resp, "text", "") or ""

        data = json.loads(text)
        norm = normalize_item(data)
        if not norm:
            raise ValueError("Geminiå¿œç­”ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
        norm["source"] = "online"

        # æˆåŠŸè¨˜éŒ²
        record_call(meter, ok=True, is_429=False)
        save_meter(meter)
        return norm

    except Exception as e:
        # 429ãªã©ã®ç›®å°
        is_429 = ("429" in str(e)) or ("Resource exhausted" in str(e)) or ("quota" in str(e).lower()) or ("rate" in str(e).lower())
        record_call(meter, ok=False, is_429=is_429)
        save_meter(meter)
        raise

# ===== å‡ºé¡Œãƒ»æ¡ç‚¹ =====
def start_online_or_offline(model_choice: str, meter: dict):
    """ã¾ãšã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«æŒ‘æˆ¦ã€‚å¤±æ•—ãªã‚‰ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã¸åˆ‡æ›¿ã€‚"""
    st.session_state.result = None
    st.session_state.picked = None
    st.session_state.model_name = None
    st.session_state.last_error = ""

    try:
        q = generate_with_gemini(model_choice, meter)
        st.session_state.question = q
        st.session_state.mode = "online"
        st.session_state.model_name = model_choice
        st.success("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼ˆGeminiï¼‰ã§å•é¡Œã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        return
    except Exception as e:
        st.session_state.last_error = str(e)
        st.info("GeminiãŒä½¿ãˆãªã„ãŸã‚ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å•é¡Œã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")

    bank = load_offline_bank()
    st.session_state.question = random.choice(bank)
    st.session_state.mode = "offline"

def grade(picked: str):
    q = st.session_state.question
    st.session_state.result = {
        "is_correct": (picked == q["correct"]),
        "picked": picked,
        "correct": q["correct"]
    }

# ===== UI: ãƒ¡ãƒ¼ã‚¿ãƒ¼è¡¨ç¤º =====
meter = load_meter()
reset_if_new_day(meter)

with st.sidebar:
    st.subheader("ä½¿ç”¨é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼")
    # ç›®å®‰ä¸Šé™ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèª¿æ•´å¯èƒ½
    c1, c2 = st.columns(2)
    with c1:
        meter["daily_limit"] = st.number_input("1æ—¥ã®ç›®å®‰å›æ•°", 1, 1000, int(meter.get("daily_limit", DEFAULT_DAILY_LIMIT)))
    with c2:
        meter["rpm_limit"] = st.number_input("1åˆ†ã®ç›®å®‰å›æ•°", 1, 60, int(meter.get("rpm_limit", DEFAULT_RPM_LIMIT)))

    used, limit, remaining, ratio = get_daily_progress(meter)
    st.progress(ratio, text=f"ä»Šæ—¥ã®ä½¿ç”¨: {used}/{limit} ï¼ˆæ®‹ã‚Š {remaining}ï¼‰")

    cnt_1m, cooldown = rpm_window_info(meter)
    st.caption(f"ç›´è¿‘60ç§’ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {cnt_1m}/{meter['rpm_limit']}")

    if meter.get("last_429_at"):
        last429 = datetime.fromisoformat(meter["last_429_at"]).astimezone(JST)
        st.caption(f"æœ€å¾Œã®429: {last429.strftime('%H:%M:%S')} JST")
    if cooldown > 0:
        st.warning(f"æ··é›‘ã®å¯èƒ½æ€§ã‚ã‚Šã€‚ç›®å®‰ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³: {cooldown} ç§’")

    if st.button("ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’æ‰‹å‹•ãƒªã‚»ãƒƒãƒˆ"):
        meter["calls_today"] = 0
        meter["call_timestamps"] = []
        meter["last_429_at"] = None
        save_meter(meter)
        st.experimental_rerun()

# ===== ãƒ¡ã‚¤ãƒ³UI =====
st.title("Gæ¤œå®šã‚¯ã‚¤ã‚ºï¼ˆGemini/ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‹ãƒ¡ãƒ¼ã‚¿ãƒ¼ï¼‰")

api_key = get_gemini_api_key()
models = list_available_models(api_key) if api_key else []
selected_model = st.selectbox(
    "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚­ãƒ¼æœªè¨­å®šæ™‚ã¯ç„¡åŠ¹ï¼‰",
    options=models if models else ["gemini-2.5-flash"],
    index=0,
    disabled=not bool(api_key),
)

st.caption("ã¾ãš Gemini ã§ç”Ÿæˆã‚’è©¦ã¿ã€å¤±æ•—æ™‚ã¯è‡ªå‹•ã§ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å•é¡Œã«åˆ‡æ›¿ã—ã¾ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«æ¨å®šãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")

if st.button("AIã§å•é¡Œã‚’ä½œã‚‹", type="primary"):
    start_online_or_offline(selected_model, meter)

q = st.session_state.question
if q:
    st.subheader("å‡ºé¡Œ")
    st.write(q["question"])

    labels = [f"{k}ï¼š{v}" for k, v in q["choices"].items()]
    default_idx = 0
    if st.session_state.picked in q["choices"]:
        default_idx = ["A", "B", "C", "D"].index(st.session_state.picked)

    chosen_label = st.radio("é¸æŠè‚¢ï¼š", options=labels, index=default_idx, key="picked_label_radio")
    st.session_state.picked = chosen_label.split("ï¼š", 1)[0]

    submit_label = "å›ç­”ã™ã‚‹ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼‰" if st.session_state.mode == "online" else "å›ç­”ã™ã‚‹ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰"
    if st.button(submit_label):
        grade(st.session_state.picked)

# çµæœã¯å•é¡Œã®ä¸‹ã«è¡¨ç¤ºï¼ˆå•é¡Œã¯æ®‹ã™ï¼‰
if st.session_state.result and st.session_state.question:
    res = st.session_state.result
    q = st.session_state.question
    st.subheader("çµæœ")

    if res["is_correct"]:
        st.success(f"æ­£è§£ï¼ é¸æŠï¼š{res['picked']} / æ­£è§£ï¼š{res['correct']}")
    else:
        st.error(f"ä¸æ­£è§£â€¦ é¸æŠï¼š{res['picked']} / æ­£è§£ï¼š{res['correct']}")

    st.markdown("**è§£èª¬ï¼ˆå…¨é¸æŠè‚¢ï¼‰**")
    for k in ["A", "B", "C", "D"]:
        head = "âœ…" if k == q["correct"] else "ãƒ»"
        st.markdown(f"{head} **{k}ï¼š{q['choices'][k]}**")
        st.write(f"è§£èª¬ï¼š{q['explanations'].get(k, 'ï¼ˆè§£èª¬ãªã—ï¼‰')}")

    if st.button("ã‚‚ã†ä¸€å•å‡ºã™"):
        st.session_state.result = None
        st.session_state.picked = None
        start_online_or_offline(selected_model, meter)

mode_info = ("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³: " + (st.session_state.model_name or "â€”")) if st.session_state.mode == "online" else "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡ºé¡Œä¸­"
if st.session_state.last_error:
    st.caption(mode_info + f"ï½œæœ€å¾Œã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {st.session_state.last_error[:80]}â€¦")
else:
    st.caption(mode_info)
