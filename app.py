# app.py
# Gæ¤œå®šã‚¯ã‚¤ã‚ºã‚¢ãƒ—ãƒªï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³=Gemini / ã‚ªãƒ•ãƒ©ã‚¤ãƒ³=å•é¡Œãƒãƒ³ã‚¯ï¼‰
# ä¾å­˜: streamlit, google-generativeai, requests
import os
import json
import random
from pathlib import Path
import streamlit as st

# ====== åŸºæœ¬è¨­å®š ======
st.set_page_config(page_title="Gæ¤œå®šã‚¯ã‚¤ã‚ºã‚¢ãƒ—ãƒª", page_icon="ğŸ§ ", layout="centered")

APP_DIR = Path(__file__).parent
DATA_DIR = APP_DIR / "data"
BANK_DIR = APP_DIR / "problem_bank"
BANK_FILE = BANK_DIR / "question_bank.jsonl"  # 1è¡Œ1å•ã®JSON Lines

# ====== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ======
def read_jsonl(path: Path):
    items = []
    if path.exists():
        with path.open("r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    items.append(json.loads(line))
                except Exception:
                    # å£Šã‚ŒãŸè¡Œã¯ç„¡è¦–
                    continue
    return items

def load_offline_bank():
    bank = read_jsonl(BANK_FILE)
    if bank:
        return bank

    # ãƒãƒ³ã‚¯ãŒç©ºã§ã‚‚æœ€ä½é™ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå•é¡Œï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰
    return [
        {
            "source": "offline_default",
            "question": "æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®èª¬æ˜ã¨ã—ã¦æœ€ã‚‚é©åˆ‡ãªã®ã¯ã©ã‚Œï¼Ÿ",
            "choices": {
                "A": "å…¥åŠ›ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹",
                "B": "æ­£è§£ãƒ©ãƒ™ãƒ«ãªã—ã§æ§‹é€ ã‚’è¦‹ã¤ã‘ã‚‹",
                "C": "å ±é…¬æœ€å¤§åŒ–ã®è¡Œå‹•ã‚’å­¦ç¿’ã™ã‚‹",
                "D": "ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ã¿ã‚’æ‰±ã†å­¦ç¿’æ³•"
            },
            "correct": "A",
            "explanations": {
                "A": "æ•™å¸«ã‚ã‚Šå­¦ç¿’ã¯å…¥åŠ›ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢ã§å­¦ç¿’ã—ã¾ã™ã€‚",
                "B": "ã“ã‚Œã¯æ•™å¸«ãªã—å­¦ç¿’ã®èª¬æ˜ã§ã™ã€‚",
                "C": "ã“ã‚Œã¯å¼·åŒ–å­¦ç¿’ã®èª¬æ˜ã§ã™ã€‚",
                "D": "ç‰¹å®šã‚¿ã‚¹ã‚¯ã®ä¸€ä¾‹ã§å­¦ç¿’è¨­å®šãã®ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
            }
        }
    ]

def ensure_state():
    if "question" not in st.session_state:
        st.session_state.question = None   # ç¾åœ¨ã®å‡ºé¡Œãƒ‡ãƒ¼ã‚¿(dict)
    if "picked" not in st.session_state:
        st.session_state.picked = None     # ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠï¼ˆ"A"ã€œ"D"ï¼‰
    if "result" not in st.session_state:
        st.session_state.result = None     # {"is_correct": bool, "reason": "..."}
    if "mode" not in st.session_state:
        st.session_state.mode = None       # "online" or "offline"
    if "model_name" not in st.session_state:
        st.session_state.model_name = None # å®Ÿéš›ã«ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«åï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ™‚ï¼‰

ensure_state()

# ====== Gemini ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡ºé¡Œ ======
def get_gemini_api_key():
    # Streamlit Cloud ã®ã€ŒSecretsã€ã« GCP ã® Gemini API ã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãŠãæƒ³å®š
    # ã‚­ãƒ¼å: GEMINI_API_KEY
    try:
        return st.secrets["GEMINI_API_KEY"]
    except Exception:
        return os.getenv("GEMINI_API_KEY")  # å¿µã®ãŸã‚ç’°å¢ƒå¤‰æ•°ã§ã‚‚æ‹¾ã†

@st.cache_data(show_spinner=False, ttl=900)
def list_available_models(api_key: str):
    """ç”Ÿæˆã«ä½¿ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆgenerateContentå¯¾å¿œï¼‰ã‚’åˆ—æŒ™ã€‚"""
    import google.generativeai as genai
    genai.configure(api_key=api_key)
    models = []
    try:
        for m in genai.list_models():
            # v0.8.x ã¯ supported_generation_methods ã‚’æŒã¤
            methods = getattr(m, "supported_generation_methods", []) or []
            if "generateContent" in methods:
                models.append(m.name)
    except Exception:
        # å–å¾—å¤±æ•—æ™‚ã¯ä»£è¡¨çš„ãªå‹•ä½œç¢ºèªæ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        models = [
            "gemini-2.0-flash",
            "gemini-2.0-flash-001",
            "gemini-2.0-flash-lite",
        ]
    return sorted(models)

def generate_with_gemini(model_name: str):
    """Geminiã§å››æŠå•é¡Œã‚’JSONã§ç”Ÿæˆã€‚æˆåŠŸã™ã‚Œã° dict ã‚’è¿”ã—ã€å¤±æ•—æ™‚ã¯ä¾‹å¤–ã‚’æŠ•ã’ã‚‹ã€‚"""
    api_key = get_gemini_api_key()
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    import google.generativeai as genai
    genai.configure(api_key=api_key)

    # PDFã¯ä»Šã¯èª­ã¿å–ã‚‰ãšï¼ˆãƒ¢ãƒã‚¤ãƒ«é‹ç”¨ã‚’å„ªå…ˆï¼‰ã€‚å¾Œã§å‰å‡¦ç†è¾æ›¸åŒ–ã™ã‚‹å‰æã€‚
    # ã“ã“ã§ã¯ä¸€èˆ¬çš„ãªGæ¤œå®šç¯„å›²ã®åŸºç¤å•é¡Œã‚’ãƒ¢ãƒ‡ãƒ«ã«ä½œã‚‰ã›ã‚‹ã€‚
    sys_prompt = (
        "ã‚ãªãŸã¯Gæ¤œå®šå¯¾ç­–ã®å•é¡Œä½œæˆè€…ã§ã™ã€‚"
        "å››æŠå•é¡Œã‚’1å•ã ã‘æ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "é¸æŠè‚¢ã¯Aã€œDã®4ã¤ã€‚æ­£ç­”ã¯1ã¤ã ã‘ã€‚"
        "å„é¸æŠè‚¢ã«çŸ­ã„è§£èª¬ã‚‚ç”¨æ„ã—ã¦ãã ã•ã„ã€‚"
        "å†…å®¹ã¯ä¸€èˆ¬çš„ãªæ©Ÿæ¢°å­¦ç¿’/ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°/çµ±è¨ˆ/å€«ç†ã‹ã‚‰åŸºæœ¬çš„ãªç¯„å›²ã€‚"
    )

    # JSONã§è¿”ã™ã‚ˆã†ã«å¼·åˆ¶
    generation_config = {
        "response_mime_type": "application/json",
        "temperature": 0.6,
        "max_output_tokens": 600,
    }

    prompt = {
        "instruction": sys_prompt,
        "format": {
            "question": "å•é¡Œæ–‡ï¼ˆ1ã€œ2æ–‡ï¼‰",
            "choices": {
                "A": "é¸æŠè‚¢A",
                "B": "é¸æŠè‚¢B",
                "C": "é¸æŠè‚¢C",
                "D": "é¸æŠè‚¢D"
            },
            "correct": "A|B|C|D ã®ã„ãšã‚Œã‹1ã¤",
            "explanations": {
                "A": "Aã®è§£èª¬ï¼ˆ1æ–‡ï¼‰",
                "B": "Bã®è§£èª¬ï¼ˆ1æ–‡ï¼‰",
                "C": "Cã®è§£èª¬ï¼ˆ1æ–‡ï¼‰",
                "D": "Dã®è§£èª¬ï¼ˆ1æ–‡ï¼‰"
            }
        }
    }

    model = genai.GenerativeModel(model_name, generation_config=generation_config)
    resp = model.generate_content(
        [
            {"role": "user", "parts": [json.dumps(prompt, ensure_ascii=False)]}
        ]
    )

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—ï¼ˆv0.8.xï¼‰
    text = ""
    try:
        text = resp.candidates[0].content.parts[0].text
    except Exception:
        text = getattr(resp, "text", "")

    data = json.loads(text)

    # æœ€ä½é™ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    req_keys = {"question", "choices", "correct", "explanations"}
    if not req_keys.issubset(set(data.keys())):
        raise ValueError("JSONã«å¿…è¦ãªã‚­ãƒ¼ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚")

    # å½¢ã‚’ãã‚ãˆã‚‹
    q = {
        "source": "online",
        "question": data["question"],
        "choices": data["choices"],
        "correct": data["correct"],
        "explanations": data["explanations"],
    }
    return q

# ====== å‡ºé¡Œãƒ•ãƒ­ãƒ¼ ======
def start_online_or_offline(model_choice: str):
    """ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©¦è¡Œâ†’å¤±æ•—ãªã‚‰ã‚ªãƒ•ãƒ©ã‚¤ãƒ³"""
    # ã¾ãšæ—¢å­˜çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆãŸã ã—ç›´å‰ã®å•é¡Œã¯ç”»é¢ã«æ®‹ã—ãŸã„ã®ã§åˆ¥ã‚­ãƒ¼ã«é€€é¿ã—ãªã„ï¼‰
    st.session_state.result = None
    st.session_state.picked = None
    st.session_state.model_name = None

    # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©¦è¡Œ
    try:
        q = generate_with_gemini(model_choice)
        st.session_state.question = q
        st.session_state.mode = "online"
        st.session_state.model_name = model_choice
        st.success("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼ˆGeminiï¼‰ã§å•é¡Œã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        return
    except Exception as e:
        # ã‚ˆãã‚ã‚‹ 429 / ç„¡å„Ÿæ 0 / ã‚­ãƒ¼æœªè¨­å®š ãªã©ã¯ã“ã“ã«æ¥ã‚‹
        st.info("GeminiãŒä½¿ãˆãªã„ãŸã‚ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å•é¡Œã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
        # print(str(e))  # å¿…è¦ãªã‚‰ãƒ­ã‚°

    # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³
    bank = load_offline_bank()
    st.session_state.question = random.choice(bank)
    st.session_state.mode = "offline"
    st.session_state.model_name = None

def grade(picked: str):
    q = st.session_state.question
    is_correct = (picked == q["correct"])
    # çµæœä¿æŒï¼ˆãƒšãƒ¼ã‚¸é·ç§»/å†å®Ÿè¡Œã§ã‚‚æ®‹ã™ï¼‰
    st.session_state.result = {
        "is_correct": is_correct,
        "picked": picked,
        "correct": q["correct"]
    }

# ====== UI ======
st.title("Gæ¤œå®šã‚¯ã‚¤ã‚ºã‚¢ãƒ—ãƒªï¼ˆGemini/ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œï¼‰")

# ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆAPIã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆã®ã¿å–å¾—ï¼‰
models = []
api_key_present = bool(get_gemini_api_key())
if api_key_present:
    models = list_available_models(get_gemini_api_key())

selected_model = st.selectbox(
    "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆGeminiãŒä½¿ãˆã‚‹æ™‚ã®ã¿æœ‰åŠ¹ï¼‰",
    options=models if models else ["gemini-2.0-flash"],
    index=0,
    disabled=not api_key_present,
)

st.caption(
    "ã€ŒAIã§å•é¡Œã‚’ä½œã‚‹ã€ã‚’æŠ¼ã™ã¨ã€ã¾ãš Gemini ã§å•é¡Œã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
    "APIãŒä½¿ãˆãªã„/ã‚¯ã‚ªãƒ¼ã‚¿0ãªã©ã®å ´åˆã¯**è‡ªå‹•çš„ã«ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å•é¡Œ**ã¸åˆ‡æ›¿ã€‚"
)

# å‡ºé¡Œãƒœã‚¿ãƒ³
if st.button("AIã§å•é¡Œã‚’ä½œã‚‹", type="primary"):
    start_online_or_offline(selected_model)

# ====== å‡ºé¡Œè¡¨ç¤º ======
q = st.session_state.question
if q:
    st.subheader("å‡ºé¡Œ")
    # å•é¡Œæ–‡ã¯å¸¸ã«æ®‹ã™
    st.write(q["question"])

    # é¸æŠ
    choice_labels = [f"{k}ï¼š{v}" for k, v in q["choices"].items()]
    # key ã‚’å›ºå®šã—ã¦å†æç”»ã§ã‚‚é¸æŠç¶­æŒ
    picked_label = st.radio(
        "é¸æŠè‚¢ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
        options=choice_labels,
        index=0 if st.session_state.picked is None else
        list(q["choices"].keys()).index(st.session_state.picked),
        key="picked_label_radio"
    )

    # ãƒ©ãƒ™ãƒ« â†’ "A"/"B"/"C"/"D" ã«æˆ»ã™
    picked_key = picked_label.split("ï¼š", 1)[0]
    st.session_state.picked = picked_key

    submit_label = "å›ç­”ã™ã‚‹ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼‰" if st.session_state.mode == "online" else "å›ç­”ã™ã‚‹ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰"
    if st.button(submit_label):
        grade(st.session_state.picked)

# ====== çµæœè¡¨ç¤ºï¼ˆå•é¡Œã¯æ®‹ã—ãŸã¾ã¾ä¸‹ã«è¡¨ç¤ºï¼‰ ======
if st.session_state.result and st.session_state.question:
    res = st.session_state.result
    q = st.session_state.question
    st.subheader("çµæœ")

    if res["is_correct"]:
        st.success(f"æ­£è§£ï¼ é¸æŠï¼š{res['picked']} / æ­£è§£ï¼š{res['correct']}")
    else:
        st.error(f"ä¸æ­£è§£â€¦ é¸æŠï¼š{res['picked']} / æ­£è§£ï¼š{res['correct']}")

    st.markdown("**è§£èª¬ï¼ˆå…¨é¸æŠè‚¢ï¼‰**")
    for key in ["A", "B", "C", "D"]:
        mark = "âœ…" if key == q["correct"] else "ãƒ»"
        st.markdown(f"{mark} **{key}ï¼š{q['choices'][key]}**")
        st.write(f"è§£èª¬ï¼š{q['explanations'].get(key, 'ï¼ˆè§£èª¬ãªã—ï¼‰')}")

    # ã‚‚ã†ä¸€å•ãƒœã‚¿ãƒ³
    if st.button("ã‚‚ã†ä¸€å•å‡ºã™"):
        # æ¬¡ã®å‡ºé¡Œã®ãŸã‚ã«çµæœã ã‘ã‚¯ãƒªã‚¢ï¼ˆå•é¡Œã¯å·®ã—æ›¿ãˆã‚‹ï¼‰
        st.session_state.result = None
        st.session_state.picked = None
        start_online_or_offline(selected_model)

# ====== ãƒ•ãƒƒã‚¿æƒ…å ± ======
with st.expander("ä½¿ã„æ–¹ï¼ˆæœ€çŸ­ï¼‰"):
    st.markdown(
        "1. ä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆAPIã‚­ãƒ¼ãŒè¨­å®šæ¸ˆã¿ã®ã¨ãï¼‰\n"
        "2. **AIã§å•é¡Œã‚’ä½œã‚‹** ã‚’æŠ¼ã™ â†’ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç”Ÿæˆã«æŒ‘æˆ¦ã—ã€ãƒ€ãƒ¡ãªã‚‰ã‚ªãƒ•ãƒ©ã‚¤ãƒ³\n"
        "3. å›ç­” â†’ çµæœã¨å…¨é¸æŠè‚¢ã®è§£èª¬ã‚’ç¢ºèª\n"
        "4. **ã‚‚ã†ä¸€å•å‡ºã™** ã§ç¹°ã‚Šè¿”ã—\n\n"
        "- PDFï¼ˆ`data/JDLA_Gtest_Syllabus_2024_v1.3_JP.pdf`ï¼‰ã¯ä»Šã¯èª­ã¿è¾¼ã¾ãšã€"
        "å°†æ¥ã®å‰å‡¦ç†ï¼ˆç« ç¯€ã”ã¨ã®è¦ç‚¹è¾æ›¸åŒ–ï¼‰ã§ä½¿ã†æƒ³å®šã§ã™ã€‚\n"
        "- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å•é¡Œã¯ `problem_bank/question_bank.jsonl`ï¼ˆ1è¡Œ1å•ã®JSONï¼‰ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã€‚"
    )

st.caption(
    ("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³: " + (st.session_state.model_name or "â€”"))
    if st.session_state.mode == "online"
    else "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡ºé¡Œä¸­"
)
