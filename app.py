# app.py
# Gæ¤œå®šã‚¯ã‚¤ã‚ºï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³=Gemini â†’ å¤±æ•—æ™‚ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰
# ä¾å­˜: streamlit, google-generativeai, pypdfï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã¯ä¸è¦ï¼‰

import os
import json
from pathlib import Path
import random
import streamlit as st

# ===== åŸºæœ¬è¨­å®š =====
st.set_page_config(page_title="Gæ¤œå®šã‚¯ã‚¤ã‚ºã‚¢ãƒ—ãƒª", page_icon="ğŸ§ ", layout="centered")

APP_DIR = Path(__file__).parent
DATA_DIR = APP_DIR / "data"
BANK_DIR = APP_DIR / "bank"                      # â† ãƒªãƒã‚¸ãƒˆãƒªã® bank/ ã‚’å‚ç…§
BANK_FILE = BANK_DIR / "question_bank.jsonl"     # 1è¡Œ1å•ã® JSON Lines

# ===== çŠ¶æ…‹ç¢ºä¿ =====
def ensure_state():
    ss = st.session_state
    ss.setdefault("question", None)     # ç¾åœ¨ã®å‡ºé¡Œï¼ˆdictï¼‰
    ss.setdefault("picked", None)       # "A"ã€œ"D"
    ss.setdefault("result", None)       # æ¡ç‚¹çµæœ
    ss.setdefault("mode", None)         # "online" / "offline"
    ss.setdefault("model_name", None)   # å®Ÿéš›ã«ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«å
ensure_state()

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
def normalize_item(item: dict) -> dict | None:
    """è¡Œã”ã¨ã®è¾æ›¸ã‚’ã‚¢ãƒ—ãƒªå†…éƒ¨ã®çµ±ä¸€å½¢å¼ã«å¤‰æ›"""
    if not isinstance(item, dict):
        return None
    q = item.get("question")
    choices = item.get("choices")
    correct = item.get("correct") or item.get("answer")

    # choices ãŒé…åˆ—ãªã‚‰ Aã€œD ã«å‰²ã‚Šå½“ã¦
    if isinstance(choices, list) and len(choices) == 4:
        choices = {k: v for k, v in zip(["A", "B", "C", "D"], choices)}

    if not q or not isinstance(choices, dict) or len(choices) != 4:
        return None
    if correct not in ["A", "B", "C", "D"]:
        return None

    return {
        "source": item.get("source", "offline"),
        "question": q,
        "choices": choices,
        "correct": correct,
        "explanations": item.get("explanations", {})
    }

def read_jsonl(path: Path) -> list[dict]:
    items = []
    if path.exists():
        with path.open("r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    raw = json.loads(line)
                except Exception:
                    continue
                norm = normalize_item(raw)
                if norm:
                    items.append(norm)
    return items

def load_offline_bank() -> list[dict]:
    bank = read_jsonl(BANK_FILE)
    if bank:
        return bank
    # ãƒãƒ³ã‚¯ãŒç©ºã®ã¨ãã®æœ€ä½é™ã®1å•
    return [{
        "source": "offline_default",
        "question": "æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®èª¬æ˜ã¨ã—ã¦æœ€ã‚‚é©åˆ‡ãªã®ã¯ã©ã‚Œï¼Ÿ",
        "choices": {
            "A": "å…¥åŠ›ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹",
            "B": "æ­£è§£ãƒ©ãƒ™ãƒ«ãªã—ã§æ§‹é€ ã‚’è¦‹ã¤ã‘ã‚‹",
            "C": "å ±é…¬æœ€å¤§åŒ–ã®è¡Œå‹•ã‚’å­¦ç¿’ã™ã‚‹",
            "D": "ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ã¿ã‚’æ‰±ã†å­¦ç¿’æ³•"
        },
        "correct": "A",
        "explanations": {
            "A": "æ•™å¸«ã‚ã‚Šå­¦ç¿’ã¯å…¥åŠ›ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢ã§å­¦ç¿’ã—ã¾ã™ã€‚",
            "B": "ã“ã‚Œã¯æ•™å¸«ãªã—å­¦ç¿’ã®èª¬æ˜ã§ã™ã€‚",
            "C": "ã“ã‚Œã¯å¼·åŒ–å­¦ç¿’ã®èª¬æ˜ã§ã™ã€‚",
            "D": "å­¦ç¿’è¨­å®šã®èª¬æ˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
        }
    }]

# ===== Geminiï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼‰ =====
def get_gemini_api_key() -> str | None:
    try:
        return st.secrets["GEMINI_API_KEY"]
    except Exception:
        return os.getenv("GEMINI_API_KEY")

@st.cache_data(show_spinner=False, ttl=900)
def list_available_models(api_key: str) -> list[str]:
    import google.generativeai as genai
    genai.configure(api_key=api_key)
    models = []
    try:
        for m in genai.list_models():
            methods = getattr(m, "supported_generation_methods", []) or []
            if "generateContent" in methods:
                models.append(m.name)
    except Exception:
        # å–å¾—å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€™è£œ
        models = ["gemini-2.5-flash", "gemini-2.0-flash", "gemini-2.0-flash-lite"]
    return sorted(models)

def generate_with_gemini(model_name: str) -> dict:
    """Geminiã§1å•ç”Ÿæˆã—å†…éƒ¨å½¢å¼ã§è¿”ã™ã€‚å¤±æ•—æ™‚ã¯ä¾‹å¤–ã‚’é€å‡ºã€‚"""
    api_key = get_gemini_api_key()
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    import google.generativeai as genai
    genai.configure(api_key=api_key)

    sys_prompt = (
        "ã‚ãªãŸã¯Gæ¤œå®šå¯¾ç­–ã®å•é¡Œä½œæˆè€…ã§ã™ã€‚å››æŠå•é¡Œã‚’1å•ã ã‘æ—¥æœ¬èªã§ä½œæˆã€‚"
        "é¸æŠè‚¢ã¯Aã€œDã§1ã¤ã ã‘æ­£è§£ã€‚å„é¸æŠè‚¢ã«1æ–‡ã®è§£èª¬ã‚’ä»˜ã‘ã‚‹ã€‚"
        "å†…å®¹ã¯æ©Ÿæ¢°å­¦ç¿’/ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°/çµ±è¨ˆ/å€«ç†ã®åŸºç¤ç¯„å›²ã‹ã‚‰ã€‚"
    )
    generation_config = {
        "response_mime_type": "application/json",
        "temperature": 0.6,
        "max_output_tokens": 600,
    }
    payload = {
        "question": "å•é¡Œæ–‡ï¼ˆ1ã€œ2æ–‡ï¼‰",
        "choices": {"A": "â€¦", "B": "â€¦", "C": "â€¦", "D": "â€¦"},
        "correct": "A|B|C|D ã®ã„ãšã‚Œã‹1ã¤",
        "explanations": {"A": "â€¦", "B": "â€¦", "C": "â€¦", "D": "â€¦"}
    }

    model = genai.GenerativeModel(model_name, generation_config=generation_config)
    resp = model.generate_content([{"role": "user", "parts": [sys_prompt, json.dumps(payload, ensure_ascii=False)]}])

    text = ""
    try:
        text = resp.candidates[0].content.parts[0].text
    except Exception:
        text = getattr(resp, "text", "") or ""

    data = json.loads(text)
    norm = normalize_item(data)
    if not norm:
        raise ValueError("Geminiå¿œç­”ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
    norm["source"] = "online"
    return norm

# ===== å‡ºé¡Œãƒ»æ¡ç‚¹ =====
def start_online_or_offline(model_choice: str):
    """ã¾ãšã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«æŒ‘æˆ¦ã€‚å¤±æ•—ãªã‚‰ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã¸åˆ‡æ›¿ã€‚"""
    st.session_state.result = None
    st.session_state.picked = None
    st.session_state.model_name = None

    try:
        q = generate_with_gemini(model_choice)
        st.session_state.question = q
        st.session_state.mode = "online"
        st.session_state.model_name = model_choice
        st.success("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼ˆGeminiï¼‰ã§å•é¡Œã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        return
    except Exception:
        st.info("GeminiãŒä½¿ãˆãªã„ãŸã‚ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å•é¡Œã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")

    bank = load_offline_bank()
    st.session_state.question = random.choice(bank)
    st.session_state.mode = "offline"

def grade(picked: str):
    q = st.session_state.question
    st.session_state.result = {
        "is_correct": (picked == q["correct"]),
        "picked": picked,
        "correct": q["correct"]
    }

# ===== UI =====
st.title("Gæ¤œå®šã‚¯ã‚¤ã‚ºï¼ˆGemini/ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œï¼‰")

api_key = get_gemini_api_key()
models = list_available_models(api_key) if api_key else []
selected_model = st.selectbox(
    "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚­ãƒ¼æœªè¨­å®šæ™‚ã¯ç„¡åŠ¹ï¼‰",
    options=models if models else ["gemini-2.0-flash"],
    index=0,
    disabled=not bool(api_key),
)

st.caption("ã¾ãš Gemini ã§ç”Ÿæˆã‚’è©¦ã¿ã€å¤±æ•—æ™‚ã¯è‡ªå‹•ã§ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å•é¡Œã«åˆ‡æ›¿ã—ã¾ã™ã€‚")

if st.button("AIã§å•é¡Œã‚’ä½œã‚‹", type="primary"):
    start_online_or_offline(selected_model)

q = st.session_state.question
if q:
    st.subheader("å‡ºé¡Œ")
    st.write(q["question"])

    # Radio ç”¨ãƒ©ãƒ™ãƒ«
    labels = [f"{k}ï¼š{v}" for k, v in q["choices"].items()]
    # ç›´å‰é¸æŠã®ç¶­æŒ
    default_idx = 0
    if st.session_state.picked in q["choices"]:
        default_idx = ["A", "B", "C", "D"].index(st.session_state.picked)

    chosen_label = st.radio(
        "é¸æŠè‚¢ï¼š", options=labels, index=default_idx, key="picked_label_radio"
    )
    st.session_state.picked = chosen_label.split("ï¼š", 1)[0]

    submit_label = "å›ç­”ã™ã‚‹ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼‰" if st.session_state.mode == "online" else "å›ç­”ã™ã‚‹ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰"
    if st.button(submit_label):
        grade(st.session_state.picked)

# çµæœã¯å•é¡Œã®ä¸‹ã«è¡¨ç¤ºï¼ˆå•é¡Œã¯æ®‹ã™ï¼‰
if st.session_state.result and st.session_state.question:
    res = st.session_state.result
    q = st.session_state.question
    st.subheader("çµæœ")

    if res["is_correct"]:
        st.success(f"æ­£è§£ï¼ é¸æŠï¼š{res['picked']} / æ­£è§£ï¼š{res['correct']}")
    else:
        st.error(f"ä¸æ­£è§£â€¦ é¸æŠï¼š{res['picked']} / æ­£è§£ï¼š{res['correct']}")

    st.markdown("**è§£èª¬ï¼ˆå…¨é¸æŠè‚¢ï¼‰**")
    for k in ["A", "B", "C", "D"]:
        head = "âœ…" if k == q["correct"] else "ãƒ»"
        st.markdown(f"{head} **{k}ï¼š{q['choices'][k]}**")
        st.write(f"è§£èª¬ï¼š{q['explanations'].get(k, 'ï¼ˆè§£èª¬ãªã—ï¼‰')}")

    if st.button("ã‚‚ã†ä¸€å•å‡ºã™"):
        st.session_state.result = None
        st.session_state.picked = None
        start_online_or_offline(selected_model)

# ãƒ•ãƒƒã‚¿
mode_info = ("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³: " + (st.session_state.model_name or "â€”")) if st.session_state.mode == "online" else "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡ºé¡Œä¸­"
st.caption(mode_info)
